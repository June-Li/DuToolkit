import os
import sys

cur_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.join(cur_dir, "../../../../")
sys.path.append(os.path.abspath(root_dir))
sys.path.append(
    os.path.abspath(os.path.join(root_dir, "MODELALG/SEG/SPLERGEMERGE/SPLERGEMERGEv0/"))
)

import argparse
import time
import numpy as np
import cv2
import pickle
import torch
from termcolor import cprint
from tqdm import tqdm
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

from MODELALG.SEG.SPLERGEMERGE.SPLERGEMERGEv0.libs.dataloader import MergeTableDataset
from MODELALG.SEG.SPLERGEMERGE.SPLERGEMERGEv0.libs.model import MergeModel


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-img",
        "--images_dir",
        default=root_dir + "/DATASETS/SEG/TableMerge/v0/test/labels_have_span/images/",
        dest="images_dir",
        help="Path to training table images (generated by prepare_data.py).",
    )
    parser.add_argument(
        "-seg",
        "--seg_dir",
        default=root_dir + "/DATASETS/SEG/TableMerge/v0/test/labels_have_span/seg/",
        dest="seg_dir",
        help="Path to training table images (generated by prepare_data.py).",
    )
    parser.add_argument(
        "-l",
        "--labels_dir",
        default=root_dir + "/DATASETS/SEG/TableMerge/v0/test/labels_have_span/labels/",
        dest="labels_dir",
        help="Path to labels for split model (generated by prepare_data.py).",
    )
    parser.add_argument(
        "-o",
        "--output_path",
        default=cur_dir + "/test_out/HKYJ_merge_test/",
        dest="output_path",
        help="Path to labels for split model (generated by prepare_data.py).",
    )
    parser.add_argument(
        "-c",
        "--checkpoints",
        default=root_dir
        + "/MODEL/SEG/SPLERGEMERGE/SPLERGEMERGEv0/TableMerge/20220706/merge_model_latest.pth",
        dest="checkpoints",
        help="Path to merge model",
    )

    configs = parser.parse_args()

    if not os.path.exists(configs.output_path):
        os.makedirs(configs.output_path)

    batch_size = 1

    cprint("Loading dataset...", "blue", attrs=["bold"])
    dataset = MergeTableDataset(
        os.getcwd(), configs.images_dir, configs.seg_dir, configs.labels_dir
    )

    # split the dataset in train and test set
    torch.manual_seed(1)
    indices = torch.randperm(len(dataset)).tolist()
    test_split = int(1 * len(indices))
    val_dataset = torch.utils.data.Subset(dataset, indices[:test_split])

    # define training and validation data loaders
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)

    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    cprint("Creating merge model...", "blue", attrs=["bold"])
    model = MergeModel()
    if configs.checkpoints:
        checkpoint = torch.load(configs.checkpoints, map_location=device)
        model.load_state_dict(checkpoint["model_state_dict"])
    model.to(device)
    model.eval()

    start_time = time.time()
    acc_T, acc_D, acc_R = 0, 0, 0
    with torch.no_grad():
        for x, (val_images, val_targets, img_path) in enumerate(tqdm(val_loader)):
            # if not img_path[0].split('/')[-1].startswith('1211924471_29_42'):
            #     continue
            # print('current img path is: ', img_path)
            filename_prefix = img_path[0].split("/")[-1][::-1].split(".", 1)[-1][::-1]
            val_images = torch.tensor(val_images, dtype=torch.float32).to(device)
            val_targets[0] = torch.tensor(val_targets[0], dtype=torch.float32).to(
                device
            )
            val_targets[1] = torch.tensor(val_targets[1], dtype=torch.float32).to(
                device
            )
            D1_probs, D2_probs, R1_probs, R2_probs = model(val_images)
            # th = 0.5
            # D1 = np.array((D1_probs.cpu().numpy().squeeze()) > th, dtype=int)
            # D2 = np.array((D2_probs.cpu().numpy().squeeze()) > th, dtype=int)
            # R1 = np.array((R1_probs.cpu().numpy().squeeze()) > th, dtype=int)
            # R2 = np.array((R2_probs.cpu().numpy().squeeze()) > th, dtype=int)
            th = 0.5
            [D1, D2, R1, R2] = map(
                lambda elem: elem.cpu().numpy().squeeze(axis=0).squeeze(axis=0),
                [D1_probs, D2_probs, R1_probs, R2_probs],
            )
            D2 = np.array(
                (D2 * ((np.max(D2, axis=0, keepdims=True) - D2) < 0.2)) > th, dtype=int
            )
            R2 = np.array(
                (R2 * ((np.max(R2, axis=1, keepdims=True) - R2) < 0.2)) > th, dtype=int
            )
            val_targets[0] = val_targets[0].cpu().numpy().squeeze(axis=0)
            val_targets[1] = val_targets[1].cpu().numpy().squeeze(axis=0)

            grid_img = val_images.cpu().numpy()[0, 3] * 255
            mask_img = cv2.imread(
                root_dir
                + "/DATASETS/SEG/TableMerge/v0/test/images/"
                + filename_prefix
                + ".png",
                0,
            )
            mask_img = cv2.resize(mask_img, grid_img.shape[::-1])
            cv2.imwrite("debug.jpg", np.hstack([mask_img, grid_img]))

            pickle.dump(
                D2, open(configs.output_path + filename_prefix + "_D2.pkl", "wb")
            )
            pickle.dump(
                R2, open(configs.output_path + filename_prefix + "_R2.pkl", "wb")
            )
            pickle.dump(
                val_targets[0],
                open(configs.output_path + filename_prefix + "_D2_target.pkl", "wb"),
            )
            pickle.dump(
                val_targets[1],
                open(configs.output_path + filename_prefix + "_R2_target.pkl", "wb"),
            )

            if (val_targets[0] == D2).all() and (val_targets[1] == R2).all():
                acc_T += 1
            if (val_targets[0] == D2).all():
                acc_D += 1
            if (val_targets[1] == R2).all():
                acc_R += 1
            continue

        total_time = time.time() - start_time
        print(
            "‚åöÔ∏èTotal time: ",
            total_time,
            "\n",
            "‚åöPer img use time: ",
            total_time / len(val_loader),
            "\n",
        )
        print(
            "üöÄACC Total is: ",
            round(acc_T / len(val_loader), 4),
            "\n",
            "üöÄACC D is: ",
            round(acc_D / len(val_loader), 4),
            "\n",
            "üöÄACC R is: ",
            round(acc_R / len(val_loader), 4),
            "\n",
        )
